{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f466179",
   "metadata": {},
   "source": [
    "# Big Exp 3 Alternative 1\n",
    "\n",
    "\n",
    "### Authors: Quentin Duchemin & Yohann De Castro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35c444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from inverse_map import inverse_map, train_network\n",
    "import torch\n",
    "import scipy\n",
    "import scipy as sc\n",
    "import scipy.stats\n",
    "from PSIGLL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a361f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected support:  [0 1 3 4 5 6]\n",
      "Size selected support:  6\n"
     ]
    }
   ],
   "source": [
    "n,p = 10000,8\n",
    "lamb = 2\n",
    "\n",
    "d = 2\n",
    "theta = 10*np.ones(d)\n",
    "truetheta = np.zeros(p)\n",
    "truetheta[:d] = theta\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "rescale = 1 #10 * np.sqrt(n)\n",
    "lamb *= rescale * lamb\n",
    "\n",
    "\n",
    "X = rescale * np.random.normal(0,1,(n,p))\n",
    "#X /= np.tile(np.linalg.norm(X,axis=0),(n,1))\n",
    "# proj = X[:,:d] @ np.linalg.inv(X[:,:d].T @ X[:,:d]) @ X[:,:d].T\n",
    "# X[:,d:] = (np.eye(n)-proj) @ X[:,d:] \n",
    "\n",
    "\n",
    "matXtrue = X[:,:d]\n",
    "\n",
    "sig = sigmoid(matXtrue @ theta)\n",
    "yobs = np.random.rand(n) <= sig\n",
    "model = LogisticRegression(C = 1/lamb, penalty='l1', solver='liblinear', fit_intercept=False)\n",
    "model.fit(X, yobs)\n",
    "theta_obs = model.coef_[0]\n",
    "M = np.where( np.abs(theta_obs) > 1e-5)[0]\n",
    "print('Selected support: ', M)\n",
    "print('Size selected support: ', len(M))\n",
    "\n",
    "\n",
    "# definition of the null distribution\n",
    "thetanull = truetheta #np.zeros(p)\n",
    "signull = sigmoid(X @ thetanull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421883eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd700661325d431d91219ddf492cb80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/3hmspmz909913ydw4nm74tq00000gn/T/ipykernel_79870/3270528783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSEI_sampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSEI_sampling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEI_by_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_ite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignull\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstatesnull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEI_by_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_ite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Yohann/Git&Bit/SIGLE/PSIGLL.py\u001b[0m in \u001b[0;36mSEI_by_sampling\u001b[0;34m(sig, X, lamb, M, remove_repetitions, nb_ite)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0mtheta_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mM2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SEI_sampling = True\n",
    "if SEI_sampling:\n",
    "    states = SEI_by_sampling(sig, X, lamb, M, nb_ite=10000000)\n",
    "    if (np.abs(signull - sig)>1e-3).any():\n",
    "        statesnull = SEI_by_sampling(signull, X, lamb, M, nb_ite=10000000)\n",
    "    else:\n",
    "        statesnull = np.copy(states)\n",
    "else:\n",
    "    probasalt, EM_states = true_conditional_distribution(theta_obs,X,yobs,lamb,truetheta,conditioning_signs=False)\n",
    "    probasnull, EM_statesnull = true_conditional_distribution(theta_obs,X,yobs,lamb,thetanull,conditioning_signs=False,states=states)\n",
    "    idxs = np.random.choice([i for i in range(len(EM_states))], size=300, p=probasalt)\n",
    "    states = [EM_states[i] for i in idxs]\n",
    "    idxs_null = np.random.choice([i for i in range(len(EM_statesnull))], size=300, p=probasnull)\n",
    "    statesnull = [EM_statesnull[i] for i in idxs_null]\n",
    "print('Number of states in the selection event: ', len(states))\n",
    "np.save('states_BE3_alt_1e1.npy', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3e307",
   "metadata": {},
   "source": [
    "##### Computing $\\bar \\pi ^{\\pi ^0}$ and training the NN aiming at computing $\\Psi=\\Xi^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9385286",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p = np.shape(X)\n",
    "matXtrue = X[:,M]\n",
    "tildeGN_12, barpi = params_saturated(signull, matXtrue, statesnull)\n",
    "#net, loss_values = train_network(matXtrue/rescale**2,max(1,truetheta[0]),nb_epochs=100,lrstart=0.1,lrdecay_step=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d56485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lspvals_selec, lspvals_sat = pval_SIGLE(states, X, M, barpi, net=None, use_net_MLE=False, l2_regularization=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8396fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_pvalues = [lspvals_selec, lspvals_sat]\n",
    "names = ['SIGLE Selected', 'SIGLE Saturated']\n",
    "plot_cdf_pvalues(lists_pvalues, names, name_figsave='alt_1e1_be3.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef2f69",
   "metadata": {},
   "source": [
    "##### Checking assumption of the Conditional CLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_upper_bound, upper_bound = upper_bound_condition_CCLT(states[:1000],X,barpi,tildeGN_12,M)\n",
    "print(\"Coarse Upper bound (Theorem statement): \", coarse_upper_bound)\n",
    "print(\"Upper bound (weaker requirement obtained in the proof): \", upper_bound)\n",
    "print(\"-> Both should tend to 0 as n grows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matXtrue = X[:,M]\n",
    "rho = matXtrue.T @ barpi.T\n",
    "try:\n",
    "    tildetheta = net(torch.from_numpy(rho.T).float())\n",
    "    tildetheta = tildetheta.detach().numpy()\n",
    "except:\n",
    "    model = LogitRegressionContinuous()\n",
    "    model.fit(matXtrue, barpi)\n",
    "    tildetheta = model.coef_\n",
    "tildeGN = matXtrue.T @ np.diag(barpi*(np.ones(n)-barpi)) @ matXtrue\n",
    "usvd,s,vt = np.linalg.svd(tildeGN)\n",
    "tildeGN_12 = usvd @ np.diag(1/np.sqrt(s)) @ vt\n",
    "GNtilde = matXtrue.T @ np.diag(sigmoid1(matXtrue @ tildetheta)) @ matXtrue\n",
    "VN = tildeGN_12 @ GNtilde\n",
    "\n",
    "lsstat = []\n",
    "u  = np.random.normal(0,1,len(M))\n",
    "u /= np.linalg.norm(u)\n",
    "u = np.zeros(len(M))\n",
    "u[0] = 1\n",
    "lspvals_selec = []\n",
    "for i in range(len(states)):\n",
    "    y = np.array(states[i])\n",
    "    # selected\n",
    "    model = LogisticRegression(C=100000000, solver='liblinear', fit_intercept=False)\n",
    "    model.fit(matXtrue, y)\n",
    "    theta = model.coef_[0]\n",
    "    stat = u.T @ VN @ (theta - tildetheta)\n",
    "    stat = u.T @ tildeGN_12 @ matXtrue.T @ (y-barpi)\n",
    "    lsstat.append(stat)\n",
    "    stat2 = np.linalg.norm( VN @ (theta - tildetheta))**2\n",
    "    lspvals_selec.append(1-scipy.stats.chi2.cdf(stat2, len(M)))\n",
    "a= plt.hist(lsstat, density=True, alpha=0.2, bins=30)\n",
    "b = np.random.normal(0,1,500)\n",
    "c = plt.hist(b,density=True, bins=30, alpha=0.2, label='true gaussian')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.hist(lspvals_selec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e1767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
